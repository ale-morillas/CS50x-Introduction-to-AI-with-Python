### [Video Link](https://youtu.be/GDAT5ZXjgh0)
# Project 5 - Traffic:
The objective of this project is to create an AI based on a Convolutional Neural Network (CNN) that will successfully identify the GTRSB traffic signals appearing in the dataset. For this, I created different designs of the neural network, with different numbers of convolutional layers of different number of filters, different kernels and different numbers of dense layers, varying their number of neurons. For each configuration, I ran three tests, which I then averaged to obtain an average result for each network. The following table shows the results obtained:

![Run Tests](/CS50_Introduction_to_AI/week_5/project_5/traffic/runs.jpg)

As can be seen, I started with a 1-layer convolutional network of 32 filters, a 3x3 kernel and a pool size of 2x2 with a hidden layer of 64 neurons and a dropout of 50% to avoid overfitting. The results were a disaster, with an accuracy of 5% and loss of 3.4978. As I changed the configuration, increasing the complexity of the network in terms of filters and neurons, I came to the conclusion that using a single convolutional layer and a hidden layer of 512 neurons, I obtained an accuracy of 93.29% and a loss of 0.3091, a quite significant improvement, although with a much higher cost of time and resources, 28 sec on average in each epoch.

Using two convolutional layers of 32 filters each and a hidden layer of 128 neurons I obtained similar results in accuracy (95%) to using the same two layers, but with 64 filters and a hidden layer of 256 neurons, but with the differences that the first model has a loss of 3% less than the second one, besides being twice as fast as the second one. Somehow with the same two convolutional layers of 64 filters and with the increase of hidden layers or neurons, the model in addition to increasing its execution time had a worse performance than the previous configurations, dropping in a range of 2-6% accuracy and with losses of 0.27-0.35, which seems to indicate that the network does not always yield good results simply by making it more complex.

By using three convolutional layers, I started to get better results. Starting with layers of 32 filters and a single hidden layer of 256 neurons, I obtained an accuracy of 94.10%. Increasing the number of hidden layers resulted in worse results overall. Finally, I decided to create the neural network with a single hidden layer of 512 neurons, first using a 3x3 kernel and dropout of 50%, yielding the best result so far, but by changing the kernel to 2x2 and dropout to 40% I obtained a slightly better accuracy (96.52%), a lower loss (0.1127) and an average time per epoch of 13 sec, being the best configuration so far in accuracy, loss and time.
